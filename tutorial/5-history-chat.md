# History Chat êµ¬í˜„

## 1. í•¨ìˆ˜ í˜¸ì¶œ íë¦„(Sequence Diagram)

![image](https://github.com/user-attachments/assets/65795d76-a522-4739-9571-17e5bf84e2e4)


## 2. get_conversation_chat_response() ë©”ì„œë“œ ì½”ë“œ ì‘ì„±

ğŸ–¥ï¸ lab/services/chat_service.py íŒŒì¼ì„ ì—´ì–´ì„œ ì½”ë“œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

ConversationChain ì„ ì‚¬ìš©í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ í˜¸ì¶œí•  ë•Œ ëŒ€í™” ë‚´ì—­ì„ ìë™ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.

```
Current conversation:

Human: Hi there!
AI Assistant: Hi there! It's nice to meet you. How can I help you today?
Human: [ ì´ë²ˆ ì…ë ¥ ]
```

[ê¸°ì¡´ ì½”ë“œ]

```python
# TODO: History ë¥¼ ê¸°ì–µí•˜ëŠ” ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
def get_conversation_chat_response(
        model_id: str, content: str, memory_window: int, model_kwargs: Dict
) -> str:
    pass
```

[ì‘ì„± ì½”ë“œ]

```python
# History ë¥¼ ê¸°ì–µí•˜ëŠ” ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
def get_conversation_chat_response(
        model_id: str, content: str, memory_window: int, model_kwargs: Dict
) -> str:
    """
    Generate a response from the conversation chain with the given input.
    """
    # 1. ChatBedrock ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    llm = ChatBedrock(
        model_id=model_id,
        model_kwargs=model_kwargs,
        streaming=True,
        callbacks=[StreamHandler(st.empty())]
    )

    # 2. ëŒ€í™”ë¥¼ í•˜ê³  ë©”ëª¨ë¦¬ì—ì„œ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë¡œë“œí•˜ëŠ” ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    # StreamlitChatMessageHistory will store messages in Streamlit session state at the specified key=.
    # The default key is "langchain_messages".
    conversation_chain = ConversationChain(
        llm=llm,
        memory=ConversationBufferWindowMemory(
            k=memory_window,
            ai_prefix='Assistant',
            chat_memory=StreamlitChatMessageHistory(),
            return_messages=True
        ),
        verbose=True
    )

    # 3. ConversationChain ì„ í˜¸ì¶œí•´ì„œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    answer = conversation_chain.predict(input=content)
    return answer
```

## 3. í…ŒìŠ¤íŠ¸

í„°ë¯¸ë„ì—ì„œ streamlit ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. 

```
cd ~/environment/aws-genai-techcamp-2024/lab/
streamlit run app.py --server.port 8080
```

Streamlit ëª…ë ¹ìœ¼ë¡œ í‘œì‹œë˜ëŠ” ë„¤íŠ¸ì›Œí¬ URL ë° ì™¸ë¶€ URL ë§í¬ëŠ” ë¬´ì‹œí•©ë‹ˆë‹¤. ëŒ€ì‹  AWS Cloud9ì˜ ë¯¸ë¦¬ë³´ê¸° ê¸°ëŠ¥ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. 

![image](https://github.com/user-attachments/assets/7ae193a5-3d7a-4dfd-a408-c15a8bedd15d)

ì•„ë˜ì™€ ê°™ì€ ì›¹ í™”ë©´ì´ í‘œì‹œë©ë‹ˆë‹¤.

![image](https://github.com/user-attachments/assets/6bad33b3-2a82-439c-b107-5b0ba7868d45)


ì™¼ìª½ ë©”ë‰´ í•˜ë‹¨ ë©”ë‰´ì—ì„œ â³ History Chat ì„ ì„ íƒí•˜ê³  ì§€ë‚œ ëŒ€í™” ë‚´ì—­ì„ ê¸°ì–µí•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.

![image](https://github.com/user-attachments/assets/0a20f882-5ee7-4edc-9bc8-06c036e69e94)
